import pandas as pd
import pickle
from sklearn.model_selection import StratifiedKFold
import os
import numpy as np
import logging
from neuroCombat.neuroCombat import neuroCombat
from sklearn.preprocessing import StandardScaler
 
import seaborn as sns
import matplotlib.pyplot as plt
import umap
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import copy

# =======================================================================================
# 1. å¯¼å…¥ç»Ÿä¸€é…ç½®
# =======================================================================================
from config import (
    RAW_DATA_DIR, PROCESSED_DATA_DIR, CV_SPLITS_DIR, EXTERNAL_DATA_DIR, COX_DATA_DIR,
    N_SPLITS, RANDOM_STATE,
    PATIENT_ID_COLUMN, TIME_COLUMN, EVENT_COLUMN,
    ensure_directories_exist
)
from logger_manager import LoggerManager

logger = logging.getLogger(__name__)
COMBAT_PARAMS = {}

# =======================================================================================
# 2. æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•°
# =======================================================================================

def mri_sequence_aware_dimensionality_reduction(features_df, target_dim=768, method='sequence_autoencoder'):
    """
    é’ˆå¯¹MRIå¤šåºåˆ—ç‰¹å¾çš„æ— ç›‘ç£é™ç»´æ–¹æ¡ˆï¼ˆç²¾ç®€ç‰ˆï¼Œä»…ä¿ç•™æ¯åºåˆ—è‡ªç¼–ç å™¨ DAEï¼‰
    
    Args:
        features_df: ç‰¹å¾æ•°æ®æ¡†ï¼ŒåŒ…å«4ä¸ªåºåˆ—çš„ç‰¹å¾ (æ¯ä¸ªåºåˆ—3072ä¸ªç‰¹å¾)
        target_dim: ç›®æ ‡ç»´åº¦ (768)
        method: é™ç»´æ–¹æ³•
            - 'sequence_autoencoder': æ¯ä¸ªåºåˆ— DAE åˆ° target_dim/n_sequences åæ‹¼æ¥
    
    Returns:
        reduced_features_df: é™ç»´åçš„ç‰¹å¾æ•°æ®æ¡†
        reducer_info: é™ç»´å™¨ä¿¡æ¯
    """
    logger.info(f"  - MRIåºåˆ—æ„ŸçŸ¥é™ç»´: {features_df.shape[1]} â†’ {target_dim} ç»´")
    logger.info(f"  - é™ç»´æ–¹æ³•: {method}")
    
    # å‡è®¾ç‰¹å¾æŒ‰åºåˆ—é¡ºåºæ’åˆ—: [T1: 0-3071, T2: 3072-6143, FLAIR: 6144-9215, T1CE: 9216-12287]
    sequence_size = 3072
    total_features = features_df.shape[1]
    n_sequences = total_features // sequence_size
    
    logger.info(f"  - æ£€æµ‹åˆ° {n_sequences} ä¸ªMRIåºåˆ—ï¼Œæ¯ä¸ªåºåˆ— {sequence_size} ä¸ªç‰¹å¾")
    
    # ä¸ºæ¯ä¸ªåºåˆ—åˆ†é…çš„ç›®æ ‡ç»´åº¦
    dim_per_sequence = target_dim // n_sequences  # 768 // 4 = 192
    
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features_df)
    
    reducer_info = {
        'scaler': scaler,
        'method': method,
        'sequence_size': sequence_size,
        'n_sequences': n_sequences,
        'dim_per_sequence': dim_per_sequence,
        'feature_names': features_df.columns.tolist()
    }
    
    if method == 'sequence_autoencoder':
        # æ–¹æ¡ˆ: æ¯åºåˆ—å»å™ªè‡ªç¼–ç å™¨ (DAE) åˆ° dim_per_sequenceï¼Œæœ€åæ‹¼æ¥
        logger.info(f"  - æ¯åºåˆ— Denoising AutoEncoder é™ç»´åˆ° {dim_per_sequence} ç»´")

        # AE è®­ç»ƒè¶…å‚ï¼ˆå¯æ ¹æ®éœ€è¦å¾®è°ƒï¼‰
        ae_hidden_dims = [1024, 384]
        ae_code_dim = dim_per_sequence
        ae_epochs = 80
        ae_batch_size = 64
        ae_lr = 1e-3
        ae_weight_decay = 1e-4
        ae_noise_std = 0.05
        ae_patience = 10

        class SeqAutoEncoder(nn.Module):
            def __init__(self, input_dim: int, code_dim: int, hidden_dims):
                super().__init__()
                h1, h2 = hidden_dims
                self.encoder = nn.Sequential(
                    nn.Linear(input_dim, h1), nn.ReLU(),
                    nn.Linear(h1, h2), nn.ReLU(),
                    nn.Linear(h2, code_dim)
                )
                self.decoder = nn.Sequential(
                    nn.Linear(code_dim, h2), nn.ReLU(),
                    nn.Linear(h2, h1), nn.ReLU(),
                    nn.Linear(h1, input_dim)
                )
            def forward(self, x):
                z = self.encoder(x)
                x_hat = self.decoder(z)
                return x_hat, z

        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        sequence_encoders_state = []
        reduced_sequences = []

        for i in range(n_sequences):
            start_idx = i * sequence_size
            end_idx = start_idx + sequence_size
            X_seq = features_scaled[:, start_idx:end_idx].astype(np.float32)

            # æ„å»ºæ•°æ®é›†
            tensor = torch.from_numpy(X_seq)
            dataset = TensorDataset(tensor)
            loader = DataLoader(dataset, batch_size=ae_batch_size, shuffle=True, num_workers=0, drop_last=False)

            # åˆå§‹åŒ–æ¨¡å‹
            model = SeqAutoEncoder(input_dim=sequence_size, code_dim=ae_code_dim, hidden_dims=ae_hidden_dims).to(device)
            opt = torch.optim.AdamW(model.parameters(), lr=ae_lr, weight_decay=ae_weight_decay)
            best_loss = float('inf')
            epochs_no_improve = 0

            model.train()
            for epoch in range(1, ae_epochs + 1):
                running = 0.0
                for (batch_x,) in loader:
                    batch_x = batch_x.to(device)
                    # å»å™ªè¾“å…¥
                    noise = ae_noise_std * torch.randn_like(batch_x)
                    noisy_x = batch_x + noise
                    opt.zero_grad()
                    recon, _ = model(noisy_x)
                    loss = nn.MSELoss()(recon, batch_x)
                    loss.backward()
                    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    opt.step()
                    running += loss.item() * batch_x.size(0)
                epoch_loss = running / len(dataset)
                if epoch % 10 == 0 or epoch == 1:
                    logger.info(f"    - åºåˆ— {i+1} AE Epoch {epoch}/{ae_epochs}, Recon Loss: {epoch_loss:.6f}")
                # ç®€å•æ—©åœ
                if epoch_loss + 1e-6 < best_loss:
                    best_loss = epoch_loss
                    epochs_no_improve = 0
                    best_state = {k: v.cpu() for k, v in model.encoder.state_dict().items()}
                else:
                    epochs_no_improve += 1
                    if epochs_no_improve >= ae_patience:
                        logger.info(f"    - åºåˆ— {i+1} æ—©åœäº epoch {epoch} (best recon={best_loss:.6f})")
                        break

            # ä¿å­˜ encoder çŠ¶æ€å¹¶æå–ç¼–ç 
            sequence_encoders_state.append(best_state)
            with torch.no_grad():
                model.encoder.load_state_dict({k: v.to(device) for k, v in best_state.items()})
                model.eval()
                codes = []
                for (batch_x,) in DataLoader(dataset, batch_size=ae_batch_size, shuffle=False):
                    batch_x = batch_x.to(device)
                    _, z = model(batch_x)
                    codes.append(z.cpu().numpy())
                seq_code = np.concatenate(codes, axis=0)
                reduced_sequences.append(seq_code)

        features_reduced = np.concatenate(reduced_sequences, axis=1)
        feature_names = []
        for i in range(n_sequences):
            for j in range(reduced_sequences[i].shape[1]):
                feature_names.append(f'Seq{i+1}_AE{j+1}')

        reducer_info['sequence_autoencoder'] = {
            'encoder_state_dicts': sequence_encoders_state,
            'hidden_dims': ae_hidden_dims,
            'code_dim': ae_code_dim,
            'input_dim': sequence_size,
            'hparams': {
                'epochs': ae_epochs,
                'batch_size': ae_batch_size,
                'lr': ae_lr,
                'weight_decay': ae_weight_decay,
                'noise_std': ae_noise_std,
                'patience': ae_patience,
            }
        }

        reduced_features_df = pd.DataFrame(features_reduced, columns=feature_names, index=features_df.index)
        logger.info(f"    - æœ€ç»ˆé™ç»´ç»“æœ: {features_df.shape[1]} â†’ {reduced_features_df.shape[1]} ç»´")
        return reduced_features_df, reducer_info
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³•: {method}")

def apply_mri_sequence_reduction(features_df, reducer_info):
    """
    åº”ç”¨å·²è®­ç»ƒçš„MRIåºåˆ—é™ç»´å™¨åˆ°æ–°æ•°æ®
    """
    if reducer_info is None:
        return features_df
    
    # æ ‡å‡†åŒ–
    features_scaled = reducer_info['scaler'].transform(features_df)
    method = reducer_info['method']
    
    if method == 'sequence_pca' or method == 'sequence_ica' or method == 'hybrid_reduction':
        # åºåˆ—æ„ŸçŸ¥æ–¹æ³•
        sequence_size = reducer_info['sequence_size']
        n_sequences = reducer_info['n_sequences']
        sequence_reducers = reducer_info['sequence_reducers']
        
        reduced_sequences = []
        
        for i in range(n_sequences):
            start_idx = i * sequence_size
            end_idx = start_idx + sequence_size
            
            sequence_data = features_scaled[:, start_idx:end_idx]
            
            if method == 'hybrid_reduction':
                # å…ˆæ–¹å·®é€‰æ‹©ï¼Œå†PCA
                variance_selector = sequence_reducers[i]['variance_selector']
                pca = sequence_reducers[i]['pca']
                
                sequence_selected = variance_selector.transform(sequence_data)
                if pca is not None:
                    sequence_reduced = pca.transform(sequence_selected)
                else:
                    sequence_reduced = sequence_selected
            else:
                # ç›´æ¥åº”ç”¨PCAæˆ–ICA
                sequence_reduced = sequence_reducers[i].transform(sequence_data)
            
            reduced_sequences.append(sequence_reduced)
        
        features_reduced = np.concatenate(reduced_sequences, axis=1)
        
    elif method == 'global_pca':
        # å…¨å±€PCA
        features_reduced = reducer_info['global_pca'].transform(features_scaled)
        
    elif method == 'variance_pca':
        # æ–¹å·®é€‰æ‹© + PCA
        top_indices = reducer_info['top_indices']
        features_selected = features_scaled[:, top_indices]
        features_reduced = reducer_info['pca'].transform(features_selected)
    elif method == 'sequence_autoencoder':
        # è¿˜åŸå¹¶åº”ç”¨æ¯åºåˆ—çš„ encoder
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        seq_info = reducer_info['sequence_autoencoder']
        enc_states = seq_info['encoder_state_dicts']
        hidden_dims = seq_info['hidden_dims']
        code_dim = seq_info['code_dim']
        input_dim = seq_info['input_dim']

        class SeqAutoEncoder(nn.Module):
            def __init__(self, input_dim: int, code_dim: int, hidden_dims):
                super().__init__()
                h1, h2 = hidden_dims
                self.encoder = nn.Sequential(
                    nn.Linear(input_dim, h1), nn.ReLU(),
                    nn.Linear(h1, h2), nn.ReLU(),
                    nn.Linear(h2, code_dim)
                )
                self.decoder = nn.Identity()
            def forward(self, x):
                z = self.encoder(x)
                return z

        reduced_sequences = []
        for i in range(reducer_info['n_sequences']):
            start_idx = i * reducer_info['sequence_size']
            end_idx = start_idx + reducer_info['sequence_size']
            X_seq = features_scaled[:, start_idx:end_idx].astype(np.float32)
            model = SeqAutoEncoder(input_dim, code_dim, hidden_dims).to(device)
            model.encoder.load_state_dict({k: v.to(device) for k, v in enc_states[i].items()})
            model.eval()
            with torch.no_grad():
                tensor = torch.from_numpy(X_seq).to(device)
                z = model(tensor).cpu().numpy()
            reduced_sequences.append(z)
        features_reduced = np.concatenate(reduced_sequences, axis=1)
    
    # é‡å»ºç‰¹å¾å
    if method == 'sequence_pca':
        feature_names = []
        for i in range(reducer_info['n_sequences']):
            for j in range(reduced_sequences[i].shape[1]):
                feature_names.append(f'Seq{i+1}_PC{j+1}')
    elif method == 'sequence_ica':
        feature_names = []
        for i in range(reducer_info['n_sequences']):
            for j in range(reduced_sequences[i].shape[1]):
                feature_names.append(f'Seq{i+1}_IC{j+1}')
    elif method == 'hybrid_reduction':
        feature_names = []
        for i in range(reducer_info['n_sequences']):
            for j in range(reduced_sequences[i].shape[1]):
                feature_names.append(f'Seq{i+1}_Hybrid{j+1}')
    elif method == 'global_pca':
        feature_names = [f'Global_PC{i+1}' for i in range(features_reduced.shape[1])]
    elif method == 'variance_pca':
        feature_names = [f'VarPCA_PC{i+1}' for i in range(features_reduced.shape[1])]
    elif method == 'sequence_autoencoder':
        feature_names = []
        for i in range(reducer_info['n_sequences']):
            # å¯¹åº” apply é˜¶æ®µ reduced_sequences çš„åˆ—æ•°
            # ç”±äºä¸èƒ½ç›´æ¥è®¿é—® reduced_sequences è¿™é‡Œï¼Œæ ¹æ® code_dim å¡«å……åç§°
            for j in range(reducer_info['dim_per_sequence']):
                feature_names.append(f'Seq{i+1}_AE{j+1}')
    
    return pd.DataFrame(features_reduced, columns=feature_names, index=features_df.index)

def apply_trained_mri_reducer(test_mri_df, mri_reducer):
    """
    å°†è®­ç»ƒå¥½çš„MRIé™ç»´å™¨åº”ç”¨åˆ°æµ‹è¯•é˜Ÿåˆ—
    """
    logger.info(f"  - å°†è®­ç»ƒå¥½çš„MRIé™ç»´å™¨åº”ç”¨åˆ° {test_mri_df.shape[0]} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # åŸºç¡€é¢„å¤„ç†ï¼šæ·»åŠ source_cohort, ç¼ºå¤±å€¼å¡«å……, æ–¹å·®ç­›é€‰
    meta_cols = [PATIENT_ID_COLUMN]
    if 'source_cohort' not in test_mri_df.columns:
        test_mri_df = test_mri_df.copy()
        test_mri_df['source_cohort'] = 'tcga'  # å‡è®¾æµ‹è¯•é˜Ÿåˆ—æ˜¯tcga
    
    meta_cols = [PATIENT_ID_COLUMN, 'source_cohort']
    meta_df = test_mri_df[meta_cols]
    features_df = test_mri_df.drop(columns=meta_cols)
    
    # å¡«å……ç¼ºå¤±å€¼
    if features_df.isnull().sum().sum() > 0:
        features_df.fillna(0, inplace=True)
        logger.info(f"    - å¡«å……äº†æµ‹è¯•é˜Ÿåˆ—çš„ç¼ºå¤±å€¼")
    
    # å¯¹é½è®­ç»ƒæ—¶çš„ç‰¹å¾åˆ—é¡ºåºï¼Œç¼ºå¤±åˆ—å¡«0ï¼Œå¤šä½™åˆ—ä¸¢å¼ƒ
    if mri_reducer is not None and 'feature_names' in mri_reducer:
        expected = mri_reducer['feature_names']
        features_df = features_df.reindex(columns=expected, fill_value=0)

    # ç›´æ¥åº”ç”¨é™ç»´å™¨
    if mri_reducer is not None:
        reduced_features_df = apply_mri_sequence_reduction(features_df, mri_reducer)
        logger.info(f"    - æµ‹è¯•é˜Ÿåˆ—MRIé™ç»´: {features_df.shape[1]} â†’ {reduced_features_df.shape[1]} ç»´")
    else:
        reduced_features_df = features_df
        logger.info(f"    - æµ‹è¯•é˜Ÿåˆ—MRIä¿æŒåŸç»´åº¦: {features_df.shape[1]} ç»´")
    
    # åˆå¹¶metaä¿¡æ¯
    final_df = pd.concat([meta_df.reset_index(drop=True), reduced_features_df.reset_index(drop=True)], axis=1)
    return final_df

def load_cohort_data(cohort_name):
    """æ ¹æ®é˜Ÿåˆ—åç§°åŠ è½½ MRI, WSI, å’Œä¸´åºŠæ•°æ®ã€‚"""
    logger.info(f"  - æ­£åœ¨åŠ è½½é˜Ÿåˆ—: {cohort_name}...")
    try:
        mri_df = pd.read_csv(os.path.join(RAW_DATA_DIR, f"{cohort_name}_mri.csv"))
        wsi_df = pd.read_csv(os.path.join(RAW_DATA_DIR, f"{cohort_name}_wsi.csv"))
        cli_df = pd.read_csv(os.path.join(RAW_DATA_DIR, f"{cohort_name}_cli.csv"))
        
        # --- ã€æ£€æŸ¥ç‚¹ã€‘æ‰“å°åŸå§‹æ•°æ®ç»´åº¦ ---
        logger.info(f"    - åŸå§‹ MRI æ•°æ®ç»´åº¦: {mri_df.shape}")
        logger.info(f"    - åŸå§‹ WSI æ•°æ®ç»´åº¦: {wsi_df.shape}")
        logger.info(f"    - åŸå§‹ä¸´åºŠæ•°æ®ç»´åº¦: {cli_df.shape}")
        
        mri_df['source_cohort'] = cohort_name
        wsi_df['source_cohort'] = cohort_name
        
        return mri_df, wsi_df, cli_df
    except FileNotFoundError as e:
        logger.error(f"  - âŒ é”™è¯¯: æ‰¾ä¸åˆ°é˜Ÿåˆ— '{cohort_name}' çš„æ•°æ®æ–‡ä»¶ã€‚ç¼ºå¤±æ–‡ä»¶: {e.filename}")
        exit()

def preprocess_and_select_features(df, modality_name, target_dim=None, reduction_method='sequence_pca'):
    """é¢„å¤„ç†ç‰¹å¾æ•°æ®ï¼šå¡«å……ç¼ºå¤±å€¼ã€ç§»é™¤ä½æ–¹å·®ç‰¹å¾ï¼Œå¹¶è¿›è¡Œæ— ç›‘ç£é™ç»´ã€‚"""
    logger.info(f"  - æ­£åœ¨é¢„å¤„ç† {modality_name} ç‰¹å¾...")
    
    meta_cols = [PATIENT_ID_COLUMN, 'source_cohort']
    meta_df = df[meta_cols]
    features_df = df.drop(columns=meta_cols)
    original_feature_count = features_df.shape[1]
    
    missing_vals = features_df.isnull().sum().sum()
    if missing_vals > 0:
        logger.info(f"    - å‘ç° {missing_vals} ä¸ªç¼ºå¤±å€¼ï¼Œç”¨ 0 å¡«å……ã€‚")
        features_df.fillna(0, inplace=True)

    # ä¿æŒç‰¹å¾å…¨é›†ä¸€è‡´ä»¥ç¡®ä¿è·¨é˜Ÿåˆ—ç‰¹å¾åå¯¹é½ï¼Œä¸ç§»é™¤æ–¹å·®ä¸º0çš„ç‰¹å¾
    features_df_selected = features_df.copy()
    
    # --- ã€æ–°å¢ã€‘MRIåºåˆ—æ„ŸçŸ¥æ— ç›‘ç£é™ç»´ ---
    reducer_info = None
    if target_dim is not None and features_df_selected.shape[1] > target_dim:
        logger.info(f"    - å¼€å§‹MRIåºåˆ—æ„ŸçŸ¥æ— ç›‘ç£é™ç»´: {features_df_selected.shape[1]} â†’ {target_dim}")
        
        if modality_name == "MRI":
            # ä½¿ç”¨MRIåºåˆ—æ„ŸçŸ¥é™ç»´
            features_df_selected, reducer_info = mri_sequence_aware_dimensionality_reduction(
                features_df_selected, 
                target_dim=target_dim, 
                method=reduction_method
            )
        else:
            # éMRIæ¨¡æ€ä¸è¿›è¡Œé™ç»´ï¼Œä¿æŒåŸå§‹ç‰¹å¾
            logger.info(f"    - {modality_name} ä¸è¿›è¡Œé™ç»´ï¼Œä¿æŒåŸå§‹ç‰¹å¾ç»´åº¦ {features_df_selected.shape[1]}")
    
    # --- ã€æ£€æŸ¥ç‚¹ã€‘æ‰“å°é¢„å¤„ç†åæ•°æ®ç»´åº¦ ---
    logger.info(f"    - å¤„ç†å {modality_name} ç‰¹å¾ç»´åº¦: ({features_df_selected.shape[0]}, {features_df_selected.shape[1]})")
        
    final_df = pd.concat([meta_df.reset_index(drop=True), features_df_selected.reset_index(drop=True)], axis=1)
    return final_df, reducer_info

def run_combat(df, modality_name):
    """å¯¹åˆå¹¶åçš„ç‰¹å¾æ•°æ®åº”ç”¨ ComBat æ ¡æ­£ã€‚"""
    logger.info(f"\n--- æ­£åœ¨å¯¹ {modality_name} ç‰¹å¾åº”ç”¨ ComBat æ ¡æ­£ ---")
    
    features = df.drop(columns=[PATIENT_ID_COLUMN, 'source_cohort'])
    covars = df[['source_cohort']]
    
    corrected_dict = neuroCombat(dat=features.T, covars=covars, batch_col='source_cohort')
    corrected_df = pd.DataFrame(corrected_dict['data'], index=features.T.index, columns=features.T.columns).T
    corrected_df[PATIENT_ID_COLUMN] = df[PATIENT_ID_COLUMN].values

    # ä¿å­˜ ComBat ä¼°è®¡å‚æ•°ï¼ˆä¸åŒ…å«æ•°æ®çŸ©é˜µæœ¬èº«ï¼‰ä»¥ä¾¿å¤ç°
    try:
        params_only = copy.deepcopy(corrected_dict)
        if 'data' in params_only:
            params_only.pop('data')
        COMBAT_PARAMS[modality_name] = params_only
    except Exception as e:
        logger.warning(f"ä¿å­˜ ComBat å‚æ•°å¤±è´¥: {e}")
    
    logger.info(f"  - âœ… {modality_name} ç‰¹å¾ ComBat æ ¡æ­£å®Œæˆã€‚")
    # --- ã€æ£€æŸ¥ç‚¹ã€‘æ‰“å°æ ¡æ­£åæ•°æ®ç»´åº¦å’Œé¢„è§ˆ ---
    logger.info(f"    - æ ¡æ­£å {modality_name} æ•°æ®ç»´åº¦: {corrected_df.shape}")
    logger.info("    - æ ¡æ­£åæ•°æ®é¢„è§ˆ (å‰5è¡Œï¼Œå‰5åˆ—):\n%s", corrected_df.iloc[:5, :5])
    
    return corrected_df
    
# =======================================================================================
# 4. å¯é€‰ï¼šUMAP å¯è§†åŒ–ï¼ˆé›†æˆè‡ª 0_explore_data_umap.pyï¼‰
# =======================================================================================

# UMAP é…ç½®ï¼ˆæ— éœ€å‘½ä»¤è¡Œï¼‰
DO_UMAP_VIS = False
# æ§åˆ¶æ˜¯å¦æ‰§è¡Œ ComBatï¼ˆä¾¿äºå¯¹æ¯”å‰åå·®å¼‚ï¼‰
DO_COMBAT = True
UMAP_N_NEIGHBORS = 15
UMAP_MIN_DIST = 0.1
UMAP_RANDOM_STATE = 42
UMAP_COLOR_PALETTE = 'viridis'
UMAP_FONT_SIZE_TITLE = 18
UMAP_FONT_SIZE_LABELS = 14
UMAP_OUTPUT_DIR = 'data_exploration_plots_umap'
os.makedirs(UMAP_OUTPUT_DIR, exist_ok=True)


def plot_umap_visualization(df: pd.DataFrame, modality_name: str, title_suffix: str):
    """å¯¹è¾“å…¥ DataFrame è¿›è¡Œ UMAP é™ç»´å¹¶ç»˜åˆ¶æ•£ç‚¹å›¾ï¼ˆæŒ‰ cohort ä¸Šè‰²ï¼‰ã€‚
    éœ€è¦ df è‡³å°‘åŒ…å« `PATIENT_ID_COLUMN` å’Œ `source_cohort` ä¸¤åˆ—ï¼Œå…¶ä½™åˆ—ä¸ºç‰¹å¾ã€‚
    """
    logger.info(f"\n--- Generating UMAP visualization for {modality_name} {title_suffix} data ---")
    if df is None or df.empty:
        logger.warning(f"Input DataFrame is empty. Skipping UMAP for {modality_name} {title_suffix}.")
        return
    if 'source_cohort' not in df.columns:
        logger.error(f"'source_cohort' column not found for {modality_name} {title_suffix}. Skipping.")
        return

    features = df.drop(columns=[PATIENT_ID_COLUMN, 'source_cohort'])
    cohorts = df['source_cohort']

    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)

    reducer = umap.UMAP(
        n_neighbors=UMAP_N_NEIGHBORS,
        min_dist=UMAP_MIN_DIST,
        n_components=2,
        random_state=UMAP_RANDOM_STATE
    )
    embedding = reducer.fit_transform(features_scaled)

    plot_df = pd.DataFrame(data=embedding, columns=['UMAP-1', 'UMAP-2'])
    plot_df['Cohort'] = cohorts.values

    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(12, 10))
    ax = sns.scatterplot(
        x='UMAP-1', y='UMAP-2',
        hue='Cohort',
        palette=UMAP_COLOR_PALETTE,
        data=plot_df,
        s=50,
        alpha=0.8,
        edgecolor='w',
        linewidth=0.5
    )
    plt.title(f'UMAP Visualization of {modality_name} Features ({title_suffix})', fontsize=UMAP_FONT_SIZE_TITLE)
    plt.xlabel('UMAP Component 1', fontsize=UMAP_FONT_SIZE_LABELS)
    plt.ylabel('UMAP Component 2', fontsize=UMAP_FONT_SIZE_LABELS)
    ax.legend(title='Cohort', fontsize='large', title_fontsize='x-large')

    save_path = os.path.join(UMAP_OUTPUT_DIR, f'umap_{modality_name}_{title_suffix.lower().replace(" ", "_")}.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    logger.info(f"  - UMAP plot saved to: {save_path}")

# =======================================================================================
# 3. ä¸»ç¨‹åº
# =======================================================================================

if __name__ == '__main__':
    # åˆå§‹åŒ–æ—¥å¿—
    from config import LOGS_DIR
    exp_name = 'prepare_data'
    log_dir = os.path.join(LOGS_DIR, exp_name)
    LoggerManager(experiment_name=exp_name, log_dir=log_dir)

    TRAIN_COHORTS = ['nanfang', 'huaqiao']
    TEST_COHORT = 'tcga'
    
    # ã€é…ç½®ã€‘MRIé™ç»´å‚æ•°
    MRI_TARGET_DIM = 768   # MRIé™ç»´ç›®æ ‡ç»´åº¦ (4åºåˆ— Ã— 192 = 768)
    
    # ã€é€‰æ‹©ã€‘MRIé™ç»´æ–¹æ³• - æ¨èåˆ†åºåˆ—é™ç»´
    MRI_REDUCTION_METHOD = 'sequence_autoencoder'  # æ”¹ä¸ºæ¯åºåˆ— DAEï¼Œæ— ç›‘ç£ä¸”ä¸å—æ ·æœ¬æ•°é™åˆ¶

    logger.info("=== MRIå¤šåºåˆ—æ— ç›‘ç£é™ç»´ + ComBat æ ¡æ­£æµç¨‹ ===")
    logger.info(f"ã€é…ç½®ã€‘MRIé™ç»´æ–¹æ³•: {MRI_REDUCTION_METHOD}")
    logger.info(f"ã€é…ç½®ã€‘MRIç›®æ ‡ç»´åº¦: {MRI_TARGET_DIM} (4åºåˆ— Ã— 192ç»´/åºåˆ—)")
    logger.info(f"ã€é…ç½®ã€‘WSI: ä¸è¿›è¡Œé™ç»´ï¼Œä¿æŒåŸå§‹768ç»´")
    logger.info(f"ã€ç­–ç•¥ã€‘åœ¨è®­ç»ƒé˜Ÿåˆ—ä¸Šè®­ç»ƒé™ç»´å™¨ï¼Œå†åº”ç”¨åˆ°æµ‹è¯•é˜Ÿåˆ—")
    ensure_directories_exist()

    logger.info("\n--- æ­¥éª¤ 1: åŠ è½½æ‰€æœ‰æŒ‡å®šé˜Ÿåˆ—çš„æ•°æ® ---")
    all_cohorts = TRAIN_COHORTS + [TEST_COHORT]
    mri_dfs, wsi_dfs, cli_dfs = [], [], []
    for cohort in all_cohorts:
        mri_df, wsi_df, cli_df = load_cohort_data(cohort)
        mri_dfs.append(mri_df); wsi_dfs.append(wsi_df); cli_dfs.append(cli_df)
    
    # åˆ†åˆ«å¤„ç†è®­ç»ƒé˜Ÿåˆ—å’Œæµ‹è¯•é˜Ÿåˆ—
    train_mri_dfs = [mri_dfs[i] for i, cohort in enumerate(all_cohorts) if cohort in TRAIN_COHORTS]
    train_wsi_dfs = [wsi_dfs[i] for i, cohort in enumerate(all_cohorts) if cohort in TRAIN_COHORTS]
    train_cli_dfs = [cli_dfs[i] for i, cohort in enumerate(all_cohorts) if cohort in TRAIN_COHORTS]
    
    test_mri_df = [mri_dfs[i] for i, cohort in enumerate(all_cohorts) if cohort == TEST_COHORT][0]
    test_wsi_df = [wsi_dfs[i] for i, cohort in enumerate(all_cohorts) if cohort == TEST_COHORT][0]
    test_cli_df = [cli_dfs[i] for i, cohort in enumerate(all_cohorts) if cohort == TEST_COHORT][0]
    
    # åˆå¹¶è®­ç»ƒé˜Ÿåˆ—æ•°æ®
    train_mri_df = pd.concat(train_mri_dfs, ignore_index=True)
    train_wsi_df = pd.concat(train_wsi_dfs, ignore_index=True)
    train_cli_df = pd.concat(train_cli_dfs, ignore_index=True)

    logger.info("\n--- æ­¥éª¤ 2: åœ¨è®­ç»ƒé˜Ÿåˆ—ä¸Šè®­ç»ƒMRIé™ç»´å™¨ ---")
    logger.info("ã€ç­–ç•¥ã€‘: åªåœ¨è®­ç»ƒé˜Ÿåˆ—ä¸Šå­¦ä¹ é™ç»´å™¨ï¼Œç¡®ä¿æ— æ•°æ®æ³„æ¼")
    
    # 2.1 åœ¨è®­ç»ƒé˜Ÿåˆ—ä¸Šè®­ç»ƒMRIé™ç»´å™¨
    train_mri_processed, mri_reducer = preprocess_and_select_features(
        train_mri_df, "MRI", 
        target_dim=MRI_TARGET_DIM, 
        reduction_method=MRI_REDUCTION_METHOD
    )
    
    # 2.2 WSIä¸é™ç»´ï¼ŒåªåšåŸºç¡€é¢„å¤„ç†
    logger.info("  - WSIæ•°æ®ä¸è¿›è¡Œé™ç»´ï¼Œä¿æŒåŸå§‹ç‰¹å¾")
    train_wsi_processed, _ = preprocess_and_select_features(
        train_wsi_df, "WSI", 
        target_dim=None,  # ä¸é™ç»´
        reduction_method=None
    )

    logger.info("\n--- æ­¥éª¤ 3: å°†è®­ç»ƒå¥½çš„é™ç»´å™¨åº”ç”¨åˆ°æµ‹è¯•é˜Ÿåˆ— ---")
    logger.info("ã€ä¼˜åŠ¿ã€‘: é¿å…æ•°æ®æ³„æ¼ï¼Œæµ‹è¯•é˜Ÿåˆ—ä½¿ç”¨è®­ç»ƒé˜Ÿåˆ—å­¦åˆ°çš„é™ç»´æ¨¡å¼")
    
    # 3.1 å¯¹æµ‹è¯•é˜Ÿåˆ—åº”ç”¨MRIé™ç»´å™¨
    test_mri_processed = apply_trained_mri_reducer(test_mri_df, mri_reducer)
    
    # 3.2 æµ‹è¯•é˜Ÿåˆ—WSIåŸºç¡€é¢„å¤„ç†
    test_wsi_processed, _ = preprocess_and_select_features(
        test_wsi_df, "WSI", 
        target_dim=None,  # ä¸é™ç»´
        reduction_method=None
    )
    
    # 3.3 åˆå¹¶æ‰€æœ‰æ•°æ®ç”¨äºComBat
    all_mri_df_processed = pd.concat([train_mri_processed, test_mri_processed], ignore_index=True)
    all_wsi_df_processed = pd.concat([train_wsi_processed, test_wsi_processed], ignore_index=True)
    all_cli_df = pd.concat([train_cli_df, test_cli_df], ignore_index=True)

    # å¯é€‰ï¼šåœ¨ ComBat å‰è¿›è¡Œ UMAP å¯è§†åŒ–
    if DO_UMAP_VIS:
        try:
            plot_umap_visualization(all_mri_df_processed, 'MRI', 'Before ComBat')
            plot_umap_visualization(all_wsi_df_processed, 'WSI', 'Before ComBat')
        except Exception as e:
            logger.warning(f"UMAP pre-ComBat visualization failed: {e}")

    logger.info("\n--- æ­¥éª¤ 4: åœ¨é™ç»´åçš„ç‰¹å¾ç©ºé—´è¿›è¡Œ ComBat æ ¡æ­£ ---")
    logger.info("ã€ä¼˜åŠ¿ã€‘: é™ç»´åçš„ç‰¹å¾ç©ºé—´æ›´ç¨³å®šï¼ŒComBatæ ¡æ­£æ•ˆæœæ›´å¥½")
    
    if DO_COMBAT and len(all_mri_df_processed['source_cohort'].unique()) > 1:
        all_mri_combat = run_combat(all_mri_df_processed, f"MRI({MRI_REDUCTION_METHOD})")
        all_wsi_combat = run_combat(all_wsi_df_processed, "WSI(åŸå§‹)")
    else:
        if not DO_COMBAT:
            logger.info("\n--- å·²å…³é—­ ComBatï¼šå°†ç›´æ¥ä½¿ç”¨é™ç»´åçš„ç‰¹å¾ ---")
        else:
            logger.info("\n--- æ£€æµ‹åˆ°åªæœ‰ä¸€ä¸ªæ•°æ®é˜Ÿåˆ—ï¼Œè·³è¿‡ ComBat æ ¡æ­£ ---")
        all_mri_combat = all_mri_df_processed.drop(columns=['source_cohort'])
        all_wsi_combat = all_wsi_df_processed.drop(columns=['source_cohort'])

    # å¯é€‰ï¼šåœ¨ ComBat åè¿›è¡Œ UMAP å¯è§†åŒ–ï¼ˆéœ€è¡¥å› cohort ä¿¡æ¯ï¼‰
    if DO_UMAP_VIS:
        try:
            # ä» pre-ComBat æ•°æ®æ˜ å°„ cohort
            mri_cohort_map = dict(zip(all_mri_df_processed[PATIENT_ID_COLUMN], all_mri_df_processed['source_cohort']))
            wsi_cohort_map = dict(zip(all_wsi_df_processed[PATIENT_ID_COLUMN], all_wsi_df_processed['source_cohort']))

            mri_combat_vis = all_mri_combat.copy()
            wsi_combat_vis = all_wsi_combat.copy()
            mri_combat_vis['source_cohort'] = mri_combat_vis[PATIENT_ID_COLUMN].map(mri_cohort_map)
            wsi_combat_vis['source_cohort'] = wsi_combat_vis[PATIENT_ID_COLUMN].map(wsi_cohort_map)

            plot_umap_visualization(mri_combat_vis, 'MRI', 'After ComBat')
            plot_umap_visualization(wsi_combat_vis, 'WSI', 'After ComBat')
        except Exception as e:
            logger.warning(f"UMAP post-ComBat visualization failed: {e}")

    logger.info("\n--- æ­¥éª¤ 5: æ‹†åˆ†æ ¡æ­£åçš„æ•°æ® ---")
    train_ids = train_cli_df[PATIENT_ID_COLUMN].tolist()
    test_ids = test_cli_df[PATIENT_ID_COLUMN].tolist()
    
    train_mri_corrected = all_mri_combat[all_mri_combat[PATIENT_ID_COLUMN].isin(train_ids)]
    train_wsi_corrected = all_wsi_combat[all_wsi_combat[PATIENT_ID_COLUMN].isin(train_ids)]
    train_labels = all_cli_df[all_cli_df[PATIENT_ID_COLUMN].isin(train_ids)]
    
    test_mri_corrected = all_mri_combat[all_mri_combat[PATIENT_ID_COLUMN].isin(test_ids)]
    test_wsi_corrected = all_wsi_combat[all_wsi_combat[PATIENT_ID_COLUMN].isin(test_ids)]
    test_labels = all_cli_df[all_cli_df[PATIENT_ID_COLUMN].isin(test_ids)]
    
    train_dev_df = pd.merge(pd.merge(train_mri_corrected, train_wsi_corrected, on=PATIENT_ID_COLUMN), train_labels, on=PATIENT_ID_COLUMN)
    external_test_df = pd.merge(pd.merge(test_mri_corrected, test_wsi_corrected, on=PATIENT_ID_COLUMN), test_labels, on=PATIENT_ID_COLUMN)
    
    # --- ã€æ£€æŸ¥ç‚¹ã€‘æ‰“å°æœ€ç»ˆæ‹†åˆ†åæ•°æ®ç»´åº¦ ---
    logger.info("  - âœ… æ•°æ®æ‹†åˆ†å®Œæˆã€‚")
    logger.info(f"    - æœ€ç»ˆè®­ç»ƒ/éªŒè¯é›†ç»´åº¦: {train_dev_df.shape}")
    logger.info(f"    - æœ€ç»ˆå¤–éƒ¨æµ‹è¯•é›†ç»´åº¦: {external_test_df.shape}")

    mri_cols = [col for col in train_mri_corrected.columns if col != PATIENT_ID_COLUMN]
    wsi_cols = [col for col in train_wsi_corrected.columns if col != PATIENT_ID_COLUMN]
    
    # ã€æ–°å¢ã€‘ä¿å­˜é™ç»´å™¨ä¿¡æ¯
    logger.info("\n--- æ­¥éª¤ 5: ä¿å­˜é™ç»´å™¨ä¿¡æ¯ ---")
    reducers_info = {
        'mri_reducer': mri_reducer,
        'mri_reduction_method': MRI_REDUCTION_METHOD,
        'mri_target_dim': MRI_TARGET_DIM,
        'mri_final_dim': len(mri_cols),
        'wsi_final_dim': len(wsi_cols),
        'train_cohorts': TRAIN_COHORTS,
        'test_cohort': TEST_COHORT,
        'train_case_ids': train_ids,
        'random_state': RANDOM_STATE,
        'umap_enabled': DO_UMAP_VIS,
        'combat_enabled': DO_COMBAT,
    }
    
    reducer_save_path = os.path.join(PROCESSED_DATA_DIR, 'dimensionality_reducers.pkl')
    with open(reducer_save_path, 'wb') as f:
        # è‹¥å¼€å¯äº† ComBatï¼Œé¢å¤–ä¿å­˜å‚æ•°
        if DO_COMBAT and COMBAT_PARAMS:
            reducers_info['combat_params'] = COMBAT_PARAMS
        pickle.dump(reducers_info, f)
    logger.info(f"âœ… é™ç»´å™¨ä¿¡æ¯å·²ä¿å­˜è‡³: {reducer_save_path}")
    logger.info(f"    - MRI({MRI_REDUCTION_METHOD}): 4åºåˆ—Ã—3072ç‰¹å¾ â†’ {MRI_TARGET_DIM} â†’ {len(mri_cols)} (æœ€ç»ˆç»´åº¦)")
    logger.info(f"    - WSI: ä¿æŒåŸç»´åº¦ {len(wsi_cols)} ç»´")
    
    logger.info(f"\n--- æ­¥éª¤ 6: ä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹åˆ›å»º {N_SPLITS}-æŠ˜äº¤å‰éªŒè¯æ–‡ä»¶ ---")
    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)
    for i, (train_idx, val_idx) in enumerate(skf.split(train_dev_df, train_dev_df[EVENT_COLUMN])):
        cv_train_df, cv_val_df = train_dev_df.iloc[train_idx], train_dev_df.iloc[val_idx]
        split_file_path = os.path.join(CV_SPLITS_DIR, f'split_{i}_data.pkl')
        data_dict = {'train': {'x_path': cv_train_df[wsi_cols].values.tolist(), 'x_rad': cv_train_df[mri_cols].values.tolist(), 'e': cv_train_df[EVENT_COLUMN].tolist(), 't': cv_train_df[TIME_COLUMN].tolist(), 'g': [0] * len(cv_train_df)}, 'test': {'x_path': cv_val_df[wsi_cols].values.tolist(), 'x_rad': cv_val_df[mri_cols].values.tolist(), 'e': cv_val_df[EVENT_COLUMN].tolist(), 't': cv_val_df[TIME_COLUMN].tolist(), 'g': [0] * len(cv_val_df)}}
        with open(split_file_path, 'wb') as f: pickle.dump(data_dict, f)
        logger.info(f"âœ… {N_SPLITS} ä¸ª .pkl åˆ†å‰²æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆåœ¨ '{CV_SPLITS_DIR}'")

    logger.info("\n--- æ­¥éª¤ 7: ä¿å­˜å¤„ç†åçš„å¤–éƒ¨æµ‹è¯•é›† ---")
    external_data_dict = {'test': {
        'x_path': external_test_df[wsi_cols].values.tolist(),
        'x_rad': external_test_df[mri_cols].values.tolist(),
        'e': external_test_df[EVENT_COLUMN].tolist(),
        't': external_test_df[TIME_COLUMN].tolist(),
        'g': [0] * len(external_test_df),
        'ids': external_test_df[PATIENT_ID_COLUMN].tolist()
    }}
    external_save_path = os.path.join(EXTERNAL_DATA_DIR, 'external_test_data.pkl')
    with open(external_save_path, 'wb') as f: pickle.dump(external_data_dict, f)
    logger.info(f"âœ… ç‹¬ç«‹çš„å¤–éƒ¨æµ‹è¯•é›† .pkl æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³ '{external_save_path}'")
    
    logger.info("\n" + "="*80)
    logger.info("ğŸ‰ MRIå¤šåºåˆ—æ— ç›‘ç£é™ç»´æµç¨‹å…¨éƒ¨å®Œæˆï¼")
    logger.info("="*80)
    logger.info(f"  - è®­ç»ƒ/éªŒè¯é˜Ÿåˆ—: {', '.join(TRAIN_COHORTS)}")
    logger.info(f"  - ç‹¬ç«‹æµ‹è¯•é˜Ÿåˆ—: {TEST_COHORT}")
    logger.info(f"  - æœ€ç»ˆè®­ç»ƒ/éªŒè¯é›†æ ·æœ¬æ•°: {len(train_dev_df)}")
    logger.info(f"  - æœ€ç»ˆå¤–éƒ¨æµ‹è¯•é›†æ ·æœ¬æ•°: {len(external_test_df)}")
    logger.info(f"  - MRIé™ç»´ç­–ç•¥: {MRI_REDUCTION_METHOD}")
    logger.info(f"  - MRIç‰¹å¾ç»´åº¦: 12,288 â†’ {len(mri_cols)}")
    logger.info(f"  - WSIç‰¹å¾ç»´åº¦: 768 â†’ {len(wsi_cols)}")
    logger.info(f"  - æ‰€æœ‰æ•°æ®å‡å·²é€šè¿‡ã€åºåˆ—æ„ŸçŸ¥é™ç»´ + ComBatã€‘å¤„ç†ï¼")
    logger.info("\nç°åœ¨æ‚¨å¯ä»¥å®‰å…¨åœ°è¿è¡Œæ‰€æœ‰æ¨¡å‹è®­ç»ƒè„šæœ¬äº†ã€‚")
    logger.info("="*80)